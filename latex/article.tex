\documentclass[11pt]{article}
\usepackage{times}
\usepackage{amsmath,amsthm,amssymb,bbold, mathtools,setspace,enumitem,epsfig,titlesec,verbatim,color,array,multirow,comment,graphicx,hyperref,blkarray}
%\usepackage[sort&compress]{natbib} % ProcB
\usepackage[super,sort&compress,comma]{natbib} % NComms
\usepackage[bf,small]{caption}
\usepackage[export]{adjustbox}
\usepackage[top=2.5cm,left=2.8cm,right=2.8cm,bottom=3.2cm]{geometry} 
\smallskip 

\definecolor{darkred}{rgb}{0.6,0,0}
\definecolor{darkblue}{rgb}{0,0.3,0.8}

\newcommand{\christian}[1]{\textcolor{blue}{{\bf CH:} #1}} 

\titleformat{\section}{\sffamily \fontsize{12}{20}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\sffamily \fontsize{11}{20}\bfseries}{\thesubsection}{1em}{}

\renewcommand{\figurename}{Supplementary Figure}


\newcommand{\FigIllustration}{{\bf Fig.~1}}

\newtheoremstyle{plainCl1}% name
{9pt}%      Space above, empty = 'usual value'
{15pt}%      Space below
{\it}% 	   Body font
{}%         Indent amount (empty = no indent, \parindent = para indent)
{\bfseries}% Thm head font
{.}%        Punctuation after thm head
{2mm}% Space after thm head: \newline = linebreak
{}%         Thm head spec

\newtheoremstyle{plainCl2}% name
{9pt}%      Space above, empty = 'usual value'
{15pt}%      Space below
{\it}% 	   Body font
{}%         Indent amount (empty = no indent, \parindent = para indent)
{\bfseries}% Thm head font
{.}%        Punctuation after thm head
{4mm}% Space after thm head: \newline = linebreak
{}%         Thm head spec

\theoremstyle{plainCl1}
\newtheorem{theorem}{Theorem}
\newtheorem{Prop}{Proposition}
\newtheorem{definition}{Definition}

\theoremstyle{plainCl2}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{Corollary}{Corollary}


\newcommand{\ALLD}{\emph{D}}

\newcommand{\A}{\mathbf{A}}
\newcommand{\abf}{\mathbf{a}}
\newcommand{\bbf}{\mathbf{b}}
\newcommand{\cbf}{\mathbf{c}}
\newcommand{\qbf}{\mathbf{q}}
\newcommand{\T}{\mathbf{T}}
\newcommand{\ubf}{\mathbf{u}}
\newcommand{\C}{\mathrm{C}}
\newcommand{\D}{\mathrm{D}}

\title{\sffamily \Large Supplementary Information\\[0.1cm] {\bfseries Introspection dynamics in asymmetric multiplayers games}}
\date{\empty}
\author{\parbox[c]{16cm}{\centering \onehalfspacing \fontsize{11}{12}\selectfont Marta Couto$^1$ and Saptarshi Pal$^1$\\[0.2cm]
$^1$Max Planck Research Group Dynamics of Social Behavior, Max Planck Institute for Evolutionary Biology, 24306~Ploen, Germany}}


\begin{document}
\maketitle
\onehalfspacing
\section*{Abstract}
\newpage
\section*{Introduction}
\section*{Model}
We consider the normal form game with $N$ players where $N > 2$. In the game, a player, say player $i$, can play actions from their action set, $\A_i := \{a_{i,1}, a_{i,2}, ..., a_{i,m_i} \}$. The action set of player $i$ has $m_i$ actions. There are, therefore, $m_i \times m_2 \times ... \times m_N$ distinct states of the game. We denote a state of the game by collecting the actions of all the players in the game in a vector, $\abf := (\abf_1, \abf_2, ..., \abf_N)$ where $\abf \in \A := \A_1 \times \A_2 \times ... \times \A_N$. We also use the notation, $\abf := (\abf_i, \abf_{-i})$ to denote the state from the perspective of player $i$. In the state $(\abf_i, \abf_{-i})$, player $i$ plays the action $\abf_i \in \A_i$ and their co-players play the action $\abf_{-i} \in \A_{-i} := \prod_{j \neq i} \A_j$. The payoff of a player depends on the state of the game. We denote the payoff of player $i$ in the state $\abf$ with $\pi_i(\abf)$ or $\pi_i(\abf_i, \abf_{-i})$. \\ \\ 
\noindent The players update their strategies over time using the introspection dynamics \cite{couto2022introspection}. At every time step, one randomly chosen player can update their strategy. The randomly chosen player, say $i$, currently playing strategy $a_{i,k}$, compares their current payoff to the payoff that they would obtain if they played a randomly selected strategy,  $a_{i,l} \neq a_{i,k}$, from their action set $\A_i$. This comparison is done while assuming that the co-players do not change their respective plays. When the co-players of player $i$ play $\abf_{-i}$, player $i$ changes to the new strategy $a_{i,l}$ from $a_{i,k}$ with the probability, \\
\begin{equation}
 p_{a_{i,k} \to a_{i,l}} (\abf_{-i})= \frac{1}{1 + e^{\displaystyle -\beta(\pi_i(a_{i,l}, \abf_{-i}) - \pi_i(a_{i,k}, \abf_{-i}))}}
 \label{Eq:introspection-update}
\end{equation}
\\ \\ \noindent in the next round. Here $\beta \in [0,\infty)$ is the selection strength parameter that represents the importance that players give to payoff differences while updating their strategies. At $\beta = 0$, players update to a randomly chosen strategy with probablity $0.5$. For $\beta > 0$, players update to new strategy with probablity greater than $0.5$ (or less than $0.5$) if the switch gives them a non-zero increase (or decrease) in the payoffs. The probability that the chosen player makes no-update is then, \\
\begin{equation}
 p_{a_{i,k} \to a_{i,k}} (\abf_{-i}) = 1 - \sum_{k \neq l} p_{a_{i,k} \to a_{i,l}} (\abf_{-i})
 \label{Eq:introspection-normalization}
\end{equation}
\\ 
Introspection dynamics can be studied by analyzing properties of the resulting transition matrix, $\T$. The transition matrix element $\T_{\abf,\bbf}$ denotes the conditional probability that the game goes to the state $\bbf$ in the next round if it is in state $\abf$ in the current round. We define the neighbourhood set of $\abf$ as the following:
\newpage
\begin{definition}[Neighbourhood set of a state] The neighbourhood set of state $\abf$, $\mathrm{Neb}(\abf)$, is defined as the following:
\begin{equation}
\mathrm{Neb}(\abf) := \{\bbf \in \A \setminus \{ \abf \}  : (\exists j) [ \bbf_{-j} = \abf_{-j} \land  \bbf_{j} \neq \abf_{j}] \}
\label{Eq:neighbourhood-states}
\end{equation} 
\label{Def:neighbourhood-states}
\end{definition} 
\noindent In other words, a state in $\mathrm{Neb}(\abf)$ is a state that has exactly one player playing a different action than in state $\abf$. Consider the game where there are  three players and each player has the identical action set $\{\C, \D \}$.  The state $(\C,\C,\C)$ is in the neighbouring set of $(\C,\C,\D)$ whereas the state $(\C,\D,\D)$ is not in the neighbourhood set of $(\C,\C, \C)$. Two states that belong in each other's neighbourhood set only differ in exactly a single player's (that we call as the index of difference) action. 

\begin{definition} [Index of difference between neighbouring states] If two states, $\abf$ and $\bbf$, satisfy $\abf \in \mathrm{Neb}(\bbf)$, the index of difference between them, $\mathrm{I}(\abf, \bbf)$, is the unique integer that satisfies:
\begin{equation}
\abf_{\mathrm{I}(\abf, \bbf)} \neq \bbf_{\mathrm{I}(\abf, \bbf)}
\end{equation} 
\label{Def:index-of-difference}
\end{definition} 
\noindent In the previous example, the index of difference between the neighbouring states $(\C,\C,\C)$ and $(\C,\C,\D)$ is $3$. The third player's action is the difference between the two neighbouring states. Using the above definitions, one can formally define the transition matrix of the introspection dynamics with:

\begin{align}
\T_{\abf, \bbf} = 
\begin{cases}
\frac{1}{N(m_j-1)}  \cdot p_{\abf_{j} \to \bbf_{j}} (\abf_{-j}) \quad  \quad &\text{ if }\bbf \in \mathrm{Neb}(\abf) \quad \text{and,} \quad j = \mathrm{I}(\abf,\bbf)\\ \\ 
0 \quad &\text{ if } \bbf \notin \mathrm{Neb}(\abf) \\ \\
1 - \sum_{\cbf \neq \bbf} \T_{\abf,\cbf} \quad &\text{ if } \abf = \bbf
\end{cases}
\label{Eq:transition-matrix}
\end{align} \\ 
\noindent The transition matrix is a row stochastic matrix (the sums of the rows are 1). This implies that the stationary distribution of $\T$: a left eigenvector of $\T$ corresponding to eigenvalue $1$, always exists. The following proposition introduces a sufficient condition for this stationary distribution to be unique. 
\begin{Prop} When $\beta$ is finite, the transition matrix of the introspection dynamics has a unique stationary distribution. 
\label{Prop:unique-stationary-dist}
\end{Prop}
\noindent \textbf{Proof:} A finite value of $\beta$ results in non-zero probability of transition between neighbouring states. Since no state is isolated (i.e., every state belongs in the neighbourhood set of another state), every state is reachable in a finite number of steps from a starting point with non-zero probability. The transition matrix $\T$ is therefore primitive for a finite $\beta$. By the Perron-Frobenius theorem, a primite matrix, $\T$ will have a unique and strictly positive stationary distribution $\ubf := (\ubf_\abf)_{\abf \in \A}$ which satisfies the conditions: 
\begin{eqnarray}
\label{Eq:lefteigenvector}
\ubf \T = \ubf \\ 
\label{Eq:normalizationcondition}
\ubf \mathbf{1} = 1
\end{eqnarray}
\noindent where $\mathbf{1}$ is the column vector with size same as $\ubf$ and has all elements as $1$. The above equations only present an explicit representation of the stationary distribution $\ubf$. The stationary distribution can be explictly calculated by the following expression (which is derived using Eq. (\ref{Eq:lefteigenvector}) and (\ref{Eq:normalizationcondition}) as:
\begin{equation}
\ubf = \mathbf{1}^\intercal (\mathbb{1} + \mathbf{U} - \T)^{-1}
\label{Eq:explicit-stationary-dist-representation}
\end{equation}
where $\mathbf{U}$ is a square matrix of size same as $\T$ with all elements 1 and $\mathbb{1}$ is the identity matrix. For all the analytical results in this paper, we consider $\beta$ to be finite so that stationary distribution of the processes are unique. The stationary distribution element $\ubf_\abf$ is the probability that state $\abf$ will be played by the players in the long run. Using the stationary distribution, one can calculate the marginal probabilities corresponding to each player's actions. For example, the probability that player $i$ plays action $a_{i,k}$ in the long run, $\xi_{i:a_{i,k}}$, can be computed as,
\begin{equation}
\mathbf{\xi}_{i:a_{i,k}} := \sum_{\qbf \in \A_{-i}} \ubf_{(a_{i,k}, \qbf)}
\label{Eq:marginal-definition}
\end{equation}
\noindent Since the stationary distribution is a probability distribution, marginal distributions also have the same property. That is, for a player $i$, 
\begin{equation}
\sum_{k = 1}^{m_i} \xi_{i:a_{i,k}}= 1
\label{Eq:marginal-prob-dist}
\end{equation}
\section*{Additive games and their properties under introspection dynamics}
In this section we discuss the stationary properties of introspection dynamics on a special class of games - the additive games \cite{pena2014gains, mcavoy2015asymmetric}. In an additive game, the payoff difference that a player earns by making a switch in their actions is independent of what their co-players play while they make this switch. In other words, if none of the co-players change their strategy, the payoff difference earned by making a particular switch is \emph{only} determined by the switch and not on the co-players' play. This property is sometimes called the \emph{equal gains from switching} \cite{pena2014gains} property of a game. That is, for any player $i$, any pair of actions $x,y \in \A_i$, and any $\qbf \in A_{-i}$,
\begin{equation}
\pi_i(x, \qbf) - \pi_i(y, \qbf) =: f_i(x,y) 
\end{equation}
\noindent For games with this property, the stationary distribution takes a simple form as shown in the proposition below.

 \begin{Prop}
When $\beta$ is finite, the unique stationary distribution, $\ubf = (\ubf_\abf)_{\abf \in \A}$, of the introspection dynamics for the N-player additive game is given by: 
\begin{equation}
\ubf_\abf = \prod_{j=1}^N \frac{1}{\displaystyle \sum_{a' \in \A_j} e^{\beta f_j(a', \abf_j)}} 
\label{Eq:additive-game-stationary-distribution}
\end{equation}
where, $f_j(a', \abf_j) = \pi_j(a', \qbf) - \pi_j(\abf_j, \qbf)$ is the co-player independent payoff difference that $j$  earns in an additive game when they unilaterally switch their play to $a'$ from $\abf_j$.
\label{Th:additive-games-stationary-dist}
\end{Prop}
\noindent The above proposition gives a closed form expression of the stationary distribution of the introspection dynamics for additive games. For any finite value of the selection parameter, $\beta$, the stationary distribution can be computed using the expression in Eq. (\ref{Eq:additive-game-stationary-distribution}). For proof, see Appendix \ref{Section:Appendix}. Additive games are particularly interesting under the introspection dynamics because of the following relationship between the stationary distribution and marginal distributions,


\begin{Prop}
Let $\ubf = (\ubf_\abf)_{\abf \in \A}$ be the unique stationary distribution of the introspection dynamics with finite $\beta$ for the N-player additive game. Then, $\ubf_\abf$ is the product of the marginal probabilities that each player plays their respective actions in $\abf$. That is, 

\begin{equation}
\ubf_\abf = \prod_{j = 1}^N \xi_{j:\abf_j}
\label{Eq:additive-game-products}
\end{equation}

\noindent where the marginal probability, $\xi_{j:\abf_j}$, is the cumulative probability that player $j$ plays $\abf_j$ at the stationary distribution. The marginal probability is given by: 

\begin{equation}
\xi_{j:\abf_j} = \frac{1}{\displaystyle \sum_{a' \in \A_j} e^{\beta f_j(a', \abf_j)}} 
\label{Eq:marginal-at-additive-game}
\end{equation}
\noindent where, $f_j(a', \abf_j) = \pi_j(a', \qbf) - \pi_j(\abf_j, \qbf)$ is the co-player independent payoff difference that $j$  earns in an additive game when they unilaterally switch their play to $a'$ from $\abf_j$.
\label{Th:additive-game-product-of-marginals}
\end{Prop}
\noindent The above proposition states that for additive games under introspection dynamics, the stationary distribution can be factorized into its corresponding marginals. In the long run, the probability that players simultaneously play ($\abf_1, \abf_2, ...,\abf_N$) is the product of the cumulative probabilities that player 1 plays $\abf_1$, player 2 plays $\abf_2$ and so on. In the following subsection we study a classical additve game - the linear public goods game under the introspection dynamics and discuss the results. 

\subsection*{Example of an additive game: linear public goods game with 2 actions}
Here, we analyze the linear public goods game with $N$-players. Each player has two possible actions, to contribute (action, $\C$), or to not contribute (action, $\D$). The players differ in their cost of cooperation and the benefit they provide to the public goods. The cost of cooperation for player $i$ and the benefit they provide to the public goods are denoted with $c_i$ and $b_i$ respectively. The payoff of player $i$ when the state of the game is $\abf$ is given by: \\
\begin{equation}
\pi_i(\abf) = \sum_{j=1}^N \frac{\displaystyle \abf_j b_j}{N} - \abf_i c_i
\label{Eq:linear-pgg-payoff}
\end{equation}
\\
\noindent The payoff difference that a player earns by unilaterally switching from $\C$ to $\D$ (or \emph{vice-versa}) in the linear public goods game is independent of what the other co-players play in the game. That is, for every player $i$,
\begin{equation}
\pi_i(\D, \qbf) - \pi_i(\C, \qbf) = c_i - \frac{b_i}{N} =: f_i(\D, \C) 
\label{Eq:difference-payoffs-lpgg}
\end{equation}\\
\noindent is independent of any $\qbf \in \A_{-i}$ that the co-players of $i$ play. The linear public goods game is therefore an example of an additive game. This property of the game results in dominated strategies for player $i$ depending on the relationship between the benefits $b_i$, number of players $N$, and cost of cooperation $c_i$. When $c_i > b_i/N$, the action of not contributing ($\D$) dominates the action of contributing ($\C$) and \emph{vice-versa}. Using proposition \ref{Th:additive-games-stationary-dist}, we derive the following closed form expression for the stationary distribution of a $N-$player linear public goods game with two strategies. 
\begin{Prop}
\label{prop:stationary-dist-lpgg}
When $\beta$ is finite, the unique stationary distribution of the introspection dynamics for a $N-$player linear public goods game is given by: 
\\
\begin{equation}
\ubf_\abf = \prod_{j = 1}^{N} \frac{1}{1 + \displaystyle e^{\mathit{sign}(\abf_j)\beta f_j(\D, \C )}} 
\label{Eq:stationary_dist_lpgg}
\end{equation}
where, 
\begin{equation}
\label{Eq:sign-function}
\mathit{sign}(a) =
\begin{cases}
1 &\quad \text{if} \quad a = \C \\
-1 &\quad \text{if} \quad a = \D
\end{cases}
\end{equation}
\end{Prop}
\newpage
\section*{Appendix: Proofs}
\label{Section:Appendix}
\begin{proof}
\textbf{Proof of Proposition} \ref{Th:additive-games-stationary-dist} \\ \\ 
Since $\beta$ is finite,the stationary distribution $\ubf = (\ubf_\abf)_{\abf \in \A}$ of the process is unique by Proposition \ref{Prop:unique-stationary-dist}. The stationary distribution also satisfies the equalities in Eq. (\ref{Eq:lefteigenvector}) and (\ref{Eq:normalizationcondition}). Before continuing through the remainder of the proof, we introduce some short-cut notation that we will be using:\\
\begin{align}
\mathrm{I}_{\bbf} &:= \mathrm{I}(\bbf,\abf), \quad \mathit{iff} \quad \bbf \in \mathrm{Neb}(\abf) \\ \notag \\ 
\label{Eq:shortcut-tau}
\tau_{j:\abf_j} &:= \frac{1}{\displaystyle \sum_{a' \in \A_j} e^{\beta f_j(a',  \abf_j)}} 
\end{align}
\noindent In order to show that the candidate stationary distribution, as proposed in Eq. (\ref{Eq:additive-game-stationary-distribution}) is the stationary distribution of the process, we need to show that the following are true:
\begin{align}
\label{step-one}
\T_{\abf,\abf} \ubf_\abf  + &\sum_{\bbf \neq \abf} \T_{\bbf, \abf} \ubf_{\bbf} = \ubf_\abf \quad \forall \abf \in \A \\[10pt]
\label{step-two}
&\sum_{\abf \in \A} \ubf_\abf  = 1
\end{align} 
Using our short-cut notation $\tau$ and the expression for our candidate stationary distribution in Eq. (\ref{Eq:additive-game-stationary-distribution}), we can express the stationary distribution as: 
\begin{equation}
\ubf_\abf = \prod_{j=1}^N \tau_{j:\abf_j}
\label{Eq:additive-stat-shortcut}
\end{equation} \\ 
Using this expression, the left hand side of Eq. (\ref{step-one}) can be simplified further with the steps: 
\begin{align}
&\T_{\abf,\abf} \ubf_\abf  + \sum_{\bbf \neq \abf} \T_{\bbf, \abf} \ubf_{\bbf}\\
&= \left( 1 - \frac{1}{N} \sum_{\bbf \in \mathrm{Neb}(\abf)} \frac{1}{m_{\mathrm{I}_\bbf}-1} \cdot p_{\abf_{\mathrm{I}_\bbf} \to \bbf_{\mathrm{I}_\bbf}} \cdot \ubf_{\abf} \right) + \sum_{\bbf \in \mathrm{Neb}(\abf)}  \frac{1}{m_{\mathrm{I}_\bbf}-1} \cdot p_{\bbf_{\mathrm{I}_\bbf} \to \abf_{\mathrm{I}_\bbf}} \cdot \ubf_{\bbf}\\ \notag \\
\label{eq:important-step}
&= \ubf_\abf +  \frac{1}{N} \sum_{\bbf \in \mathrm{Neb}(\abf)} \left( \prod_{k \neq I_\bbf} \tau_{k:\abf_k} \right) \left( p_{\bbf_{I_\bbf} \to \abf_{\mathrm{I}_\bbf}} \cdot \tau_{\mathrm{I}_\bbf: \abf_{\mathrm{I}_\bbf}} -  p_{\abf_{\mathrm{I}_\bbf} \to \bbf_{\mathrm{I}_\bbf}} \cdot \tau_{\mathrm{I}_\bbf: \bbf_{\mathrm{I}_\bbf}} \right) \cdot \left(  \frac{1}{m_{\mathrm{I}_\bbf}-1} \right)
\end{align}
\noindent For an additive game, the expressions for $p_{\bbf_{I_\bbf} \to \abf_{\mathrm{I}_\bbf}}$ and $p_{\abf_{\mathrm{I}_\bbf} \to \bbf_{\mathrm{I}_\bbf}}$ can be simply written as: 
\begin{align}
p_{\bbf_{I_\bbf} \to \abf_{\mathrm{I}_\bbf}} &=\frac{1}{1 + \displaystyle e^{\beta f_{\mathrm{I}_\bbf}(\bbf_{\mathrm{I}_\bbf}, \abf_{\mathrm{I}_\bbf})}} \\[10pt] 
p_{\abf_{\mathrm{I}_\bbf} \to \bbf_{\mathrm{I}_\bbf}} &= \frac{1}{1 + \displaystyle e^{\beta f_{\mathrm{I}_\bbf}(\abf_{\mathrm{I}_\bbf}, \bbf_{\mathrm{I}_\bbf})}} 
\end{align} \\
Using the above expressions and the expression for $\tau$ in Eq. (\ref{Eq:shortcut-tau}), it can be shown that: 
\begin{equation}
\left( p_{\bbf_{I_\bbf} \to \abf_{\mathrm{I}_\bbf}} \cdot \tau_{\mathrm{I}_\bbf: \abf_{\mathrm{I}_\bbf}} -  p_{\abf_{\mathrm{I}_\bbf} \to \bbf_{\mathrm{I}_\bbf}} \cdot \tau_{\mathrm{I}_\bbf: \bbf_{\mathrm{I}_\bbf}} \right) = 0 
\label{important-step-is-zero}
\end{equation}
\\ \noindent After plugging the equality in Eq. (\ref{important-step-is-zero}) into Eq. (\ref{eq:important-step}), we see that the left hand side of Eq. (\ref{step-one}) simplifies to $\ubf_{\abf}$. Now, to complete the proof we must check if Eq. (\ref{step-two}) holds for our candidate distribution. Summing up the elements of the stationary distribution $\ubf_\abf$ for all states $\abf \in \A$: \\ 
\begin{align}
\sum_{\abf \in \A} \ubf_\abf &= \sum_{\abf \in \A} \prod_{k=1}^N \tau_{k:\abf_k} = \sum_{\abf \in \A} \frac{\displaystyle \prod_{k=1}^N e^{\beta \pi_k(\abf_k, \qbf_{-k})}}{\displaystyle \quad \prod_{k=1}^N \sum_{a' \in \A_k} e^{\beta \pi_k(a',\qbf_{-k})}}
\end{align}
%\\ \notag \\
%\label{step-prod-sum-sum-prod}
%&= \left( \prod_{k=1}^N \sum_{\abf' \in \A} \displaystyle e^{\beta \pi^k_{\abf'}}\right)^{-1} \cdot \left( \sum_{\abf \in \A} \prod_{k=1}^N \displaystyle e^{\beta \pi^k_{\abf^k}} \right) \\ \notag \\
%\label{step-prod-is-one}
%&= 1
\noindent \\ \\ where $\qbf_{-1}, \qbf_{-2},...,\qbf_{-N}$ are fixed tuples from $\A_{-1}, \A_{-2},...,\A_{-N}$ respectively. The denominator in the above expression can be taken out completely from the first sum. That is, 
\begin{align}
\sum_{\abf \in \A} \ubf_\abf = &\sum_{\abf \in \A} \frac{\displaystyle \prod_{k=1}^N e^{\beta \pi_k(\abf_k, \qbf_{-k})}}{\displaystyle \quad \prod_{k=1}^N \sum_{a' \in \A_k} e^{\beta \pi_k(a',\qbf_{-k})}} \\[15pt]
=& \left( \displaystyle \prod_{k=1}^N \left( e^{\beta \pi_k(a_{k,1}, \qbf_{-k})}+... + e^{\beta \pi_k(a_{k,m_k}, \qbf_{-k})} \right) \right)^{-1} \cdot \left( \sum_{\abf \in \A} \displaystyle \prod_{k=1}^N e^{\beta \pi_k(\abf_k, \qbf_{-k})} \right) \\
\end{align} \\
\noindent Multiplying out the sums in the denominator of the above expression, we get that:
\begin{align}
\sum_{\abf \in \A} \ubf_\abf =& \left( \displaystyle \prod_{k=1}^N \left( e^{\beta \pi_k(a_{k,1}, \qbf_{-k})}+... + e^{\beta \pi_k(a_{k,m_k}, \qbf_{-k})} \right) \right)^{-1} \cdot \left( \sum_{\abf \in \A} \displaystyle \prod_{k=1}^N e^{\beta \pi_k(\abf_k, \qbf_{-k})} \right) \\[10pt]
=& \left( \sum_{\abf \in \A} \displaystyle \prod_{k=1}^N e^{\beta \pi_k(\abf_k, \qbf_{-k})}  \right)^{-1} \left( \sum_{\abf \in \A} \displaystyle \prod_{k=1}^N e^{\beta \pi_k(\abf_k, \qbf_{-k})}  \right) = 1
\end{align}
\noindent Therefore, the stationary distribution sums up to 1. The candidate distribution we propose for the additive game is the unique stationary distribution of the process.
\end{proof}

\begin{proof}
\textbf{Proof of Proposition} \ref{Th:additive-game-product-of-marginals} \\ \\ 
If $\ubf$ is the unique stationary distribution of the $N-$player additive game with under the finite selection introspection dynamics, it is given by the expression in Eq. \ref{Eq:additive-game-stationary-distribution}. We calculate the marginal distribution of any arbitrary state $\abf$, $\xi_{\abf} = (\xi^j_{\abf^j})_{j = 1,2,...,N}$ by using the definition of marginal distribution in Eq. \ref{Eq:marginal-definition}. It follows that: 
\begin{align}
\xi^j_{\abf^j} &= \sum_{\mathbf{b} \in \A^{-j}} \ubf_{(\abf^j,\mathbf{b})} \\ \notag \\
&= \left( \prod_{k=1}^N \sum_{\abf' \in \A^k} \displaystyle e^{\beta \pi^k_{\abf'}}\right)^{-1} \cdot \displaystyle e^{\beta \pi^j_{\abf^j}} \cdot \left( \sum_{\mathbf{b} \in \A^{-j}} \prod_{k \neq j} e^{\beta \pi^k_{\mathbf{b}^k}} \right) \\ \notag \\
&= \left( \sum_{\abf' \in \A^j} \displaystyle e^{\beta \pi^j_{\abf'}}\right)^{-1} \cdot \displaystyle e^{\beta \pi^j_{\abf^j}} \cdot \left( \prod_{k\neq j} \sum_{\abf' \in \A^k} \displaystyle e^{\beta \pi^k_{\abf'}}\right)^{-1} \cdot \left( \sum_{\mathbf{b} \in \A^{-j}} \prod_{k \neq j} e^{\beta \pi^k_{\mathbf{b}^k}} \right) \\ \notag \\ 
&= \left( \sum_{\abf' \in \A^j} \displaystyle e^{\beta \pi^j_{\abf'}}\right)^{-1} \cdot \displaystyle e^{\beta \pi^j_{\abf^j}} \cdot \left( \sum_{\abf' \in \A^{-j}} \prod_{k\neq j}  \displaystyle e^{\beta \pi^k_{\abf'}}\right)^{-1} \cdot \left( \sum_{\mathbf{b} \in \A^{-j}} \prod_{k \neq j} e^{\beta \pi^k_{\mathbf{b}^k}} \right) \\ \notag \\ 
&= \left( \sum_{\abf' \in \A^j} \displaystyle e^{\beta \left( \pi^j_{\abf'} - \pi^j_{\abf^j}\right)}\right)^{-1}
\end{align}
\noindent Therefore, the marginal distribution follows Eq.  \ref{Eq:marginal-at-additive-game}. Now since we also additionally know that the stationary distribution follows the form Eq. \ref{Eq:additive-game-stationary-distribution}, we can conclude that for additive games, under introspection dynamics with finite selection, Eq. \ref{Eq:additive-game-products} holds. 
\end{proof}

\begin{proof}
\textbf{Proof of Proposition} \ref{prop:stationary-dist-lpgg} \\ \\
Since we have demonstrated that the linear public goods game is an additive game, the proof of this theorem can be performed by directly using Theorem \ref{Th:additive-games-stationary-dist}. Here, we provide an independent proof. The idea behind this proof is identical to the proof of Theorem \ref{Th:additive-games-stationary-dist}. \\ \\
\noindent The stationary transition matrix $\T$ for the linear public goods game is primitive when $\beta$ is finite (i.e., there is a positive power $k$ such that $\T^k$ is a strictly positive matrix). Therefore, the stationary distribution of $\T$ will always be unique. We define the following short cut notations for the ease of the proof: 
\begin{eqnarray}
\bar{\abf}^j &:= \{\D,\C\} \setminus \abf^j  \\ 
p^j &:= \frac{1}{1 + \displaystyle e^{\beta f(c^j, r^j)}} 
\end{eqnarray}
In addition we introduce a mapping function $\alpha(.)$ which maps the action $\C$ to 1 and the action $\D$ to 0. That is $\alpha(\C) := 1$ and $\alpha(\D) := 0$. Using these notations and Eq. \ref{Eq:introspection-update} and \ref{Eq:difference-payoffs-lpgg} we can write the probability that a player $j$ updates from $\abf^j$ to $\bar{\abf}^j$ while their co-players play $\abf^{-j}$ as: \\
\begin{equation}
p^j_{\displaystyle \bar{\abf}^j  \to \abf^j} (\abf^{-j}) = p^j \mathit{sign}(\abf^j) + \alpha(\bar{\abf}^j) \\ \\
\end{equation}
The candidate stationary distribution $\ubf$ given in Eq \ref{Eq:stationary_dist_lpgg} can be written down using our shortcut notation as: 
\begin{equation}
\label{Eq:stationary-dist-shortcut}
\ubf_\abf = \prod_{k = 1}^{N}  p^k \mathit{sign}(\abf^k) + \alpha(\bar{\abf}^k) \quad ,\forall \abf \in \{0,1\}^N
\end{equation}
This stationary distribution must satisfy the following properties, which are also given in Eq  \ref{Eq:lefteigenvector} and \ref{Eq:normalizationcondition}:
\begin{align}
\label{Eq:transition-in-proof}
&\ubf_\abf = \T_{\abf,\abf} \ubf_\abf  + \sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q}  \\[10pt] 
\label{Eq:normalization-in-proof}
&\sum_{\forall \abf_q} \ubf_{\abf_q}= 1
\end{align}
Where, the terms in the right hand side of Eq. \ref{Eq:transition-in-proof} can be simplified using Eq \ref{Eq:introspection-update} and \ref{Eq:transition-matrix} as follows:
\begin{eqnarray}
\T_{\abf,\abf} = 1 - \sum_{k=1}^{N} \T_{(\abf^k, \abf^{-k}), (\bar{\abf}^k,\abf^{-k})} = 1 - \frac{1}{N} \sum_{k=1}^{N} p^k \textit{sign}(\bar{\abf}^k) + \alpha(\abf^k)
\label{Eq:first-term-rhs-proof}
\end{eqnarray} 
and additionally, also using Eq. \ref{Eq:stationary-dist-shortcut} the second term can be simplified too:
\begin{align}
\sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q} &= \sum_{k = 1}^N \T_{(\bar{\abf}^k,\abf^{-k}), (\abf^k, \abf^{-k})} \ubf_{(\bar{\abf}^k,\abf^{-k})} \\[10pt]
&= \frac{1}{N} \sum_{k = 1}^N \left(p^k \textit{sign}(\abf^k) +\alpha(\bar{\abf}^k) \right) \ubf_{(\bar{\abf}^k,\abf^{-k})} \\[10pt] 
\label{Eq:second-term-rhs-proof}
&= \frac{\ubf_\abf}{N} \sum_{k=1}^{N} p^k \textit{sign}(\bar{\abf}^k) + \alpha(\abf^k) 
\end{align}
Now, using Eq. \ref{Eq:first-term-rhs-proof}, \ref{Eq:second-term-rhs-proof} one can show that the right hand side of Eq. \ref{Eq:transition-in-proof} is the element of the stationary distribution, corresponding to the state $\abf$, $\ubf_a$.  Now, to complete the proof, we must show that Eq. \ref{Eq:normalization-in-proof} is also true for our candidate stationary distribution. This can be done by decomposing the sum of the elements of the stationary distribution as follows:
\begin{align}
\sum_{\forall \abf_q} u_{\abf_q} =& \displaystyle \sum_{\forall \abf_q} \prod_{k=1}^N p^k \mathit{sign}(\abf_q^k) + \alpha(\bar{\abf}_q^k) \\[10pt]
=& \displaystyle \displaystyle \sum_{\forall \abf_q} (1-p^N)  \prod_{k=1}^{N-1} p^k \mathit{sign}(\abf_q^k) + \alpha(\bar{\abf}_q^k)  + p^N  \prod_{k=1}^{N-1} p^k \mathit{sign}(\abf_q^k) + \alpha(\bar{\abf}_q^k) \\[10pt]
=& \displaystyle \sum_{\forall \abf_q} \prod_{k=1}^{N-1} p^k \mathit{sign}(\abf_q^k) + \alpha(\bar{\abf}_q^k)
\end{align}
When the above decomposition is perfomed $N-1$ more times, the sum of the right hand side becomes 1. This prooves that the candidate stationary distribution is also a probability distribution.
\end{proof}

\begin{proof}
\textbf{Proof of Proposition} \ref{Prop:Symmetric-2-strategies-state} \\ \\
By construction, the candidate stationary distribution given by Eq. \ref{Eq:stationary-dist-symm-2-stgs-state} and Eq. \ref{Eq:stationary-dist-normalization-symm-2-stgs-state} is a probability distribution since it satisfies the condition in Eq. \ref{Eq:normalizationcondition} and for any state $\abf'$, $\ubf_{\abf'}$ is between 0 and 1.  Moreover, since $\beta$ is finite, the transition matrix of the process $\T$ is primitive and therefore, it will have a unique stationary distribution. To show that the candidate stationary distribution is the unique stationary distribution, we need to check if for this process, $\ubf \T= \ubf$. That is, the condition in Eq. \ref{Eq:transition-in-proof} must hold for all states $\abf$. We re-introduce some notations that we will use in this proof: 
\begin{align}
\bar{\abf}^j &:= \{\D,\C\} \setminus \abf^j \\[10pt]
\alpha(a)&:= 
\begin{cases}
1 \quad \text{if} \quad a = \C \\[10pt]
0 \quad \text{if} \quad a = \D 
\end{cases}\\[10pt]
\mathcal{C}(\abf) &= \sum_{j=1}^N \alpha(\abf^j)
\end{align}
For this process, the first term in the right hand side of Eq. \ref{Eq:transition-in-proof} can be simplified as: 
\begin{align}
\ubf_{\abf} \T_{\abf,\abf}  &= \ubf_\abf - \ubf_{\abf} \sum_{k=1}^{N} \T_{(\abf^k, \abf^{-k}),(\bar{\abf}^{k}, \abf^{-k})} \\[10pt]
&= \ubf_{\abf} - \frac{\ubf_{\abf}}{N} \sum_{k=1}^N \frac{1}{1 + \displaystyle e^{\mathit{sign}(\bar{\abf}^{k}) \beta f(N_k)}}
\label{Eq:T_aa_u_a term}
\end{align}
\\ \noindent Where, the function $\mathit{sign}(.)$ is  defined as in Eq. \ref{Eq:sign-function} and$f(j)$ is the difference in payoffs between playing $\D$ and $\C$ when there are $j$ co-players playing $\C$. The term $N_k$ is the number of co-players of $k$ that play $\C$ in state $\abf$. That is,
\begin{equation}
N_k := \sum_{j \neq k} \alpha(\abf^j)
\end{equation}
The second term in the right hand side of Eq. \ref{Eq:transition-in-proof} can be simplified as, 
\begin{align}
\sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q} &= \sum_{k=1}^N \T_{(\bar{\abf}^k, \abf^{-k}),(\abf^k, \abf^{-k})} \ubf_{(\bar{\abf}^k, \abf^{-k})} \\[10pt]
\label{Eq:step-single-product}
&= \frac{1}{N \Gamma} \sum_{k=1}^N \T_{(\bar{\abf}^k, \abf^{-k}),(\abf^k, \abf^{-k})} \displaystyle \prod_{j=1}^{\mathcal{C}((\bar{\abf}^k, \abf^{-k}))} e^{-\beta f(j-1)}\\[10pt]
&=  \frac{1}{N \Gamma} \sum_{k=1}^N \T_{(\bar{\abf}^k, \abf^{-k}),(\abf^k, \abf^{-k})} \displaystyle \left( \prod_{j=1}^{N_k}  e^{-\beta f(j-1)} \right) \cdot e^{-\beta \alpha(\bar{\abf}^k)f(-\alpha(\abf^k)+ N_k}
\label{Eq:step-product-broken}
\end{align}
Between the steps, Eq. \ref{Eq:step-single-product} and \ref{Eq:step-product-broken}, we took out one term from the product that is present in our candidate distribution. This term accounts for the $k^{th}$ players action in the neighbouring state $(\bar{\abf}^k, \abf^{-k})$ of $\abf$. For simplicity, we replace $\T_{(\bar{\abf}^k, \abf^{-k}),(\abf^k, \abf^{-k})}$ with just $\T$ in the next steps. We continue the simplification of Eq. \ref{Eq:step-product-broken} in the later steps by introducing terms that cancel each other. \\[10pt]
\begin{align}
\sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q} &=  \frac{1}{N \Gamma} \sum_{k=1}^N \T \cdot \displaystyle \left( \prod_{j=1}^{N_k}  e^{-\beta f(j-1)} \right) \cdot \frac{e^{-\beta \alpha(\bar{\abf}^k)f(-\alpha(\abf^k)+ N_k)}}{e^{-\beta \alpha(\abf^k)f(-\alpha(\bar{\abf}^k) +N_k)}} \cdot e^{-\beta \alpha(\abf^k)f(-\alpha(\bar{\abf}^k) + N_k)}
\label{Eq:new-cancelable-term-introduced}
\end{align}
\\ \noindent The newly introduced term in Eq. \ref{Eq:new-cancelable-term-introduced} can be taken inside the product. Note that this term is 0 if the $k^{th}$ player plays $\D$ in the state $\abf$. When this term is taken inside the product bracket, products of exponent $e^{-\beta f(j-1)}$ can be performed for $j$ ranging from $1$ to the number of cooperators in state $\abf$, $\mathcal{C}(\abf)$. This product is then the stationary distribution probability $\ubf_\abf$. That is, 
\begin{align}
\sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q} &=  \frac{1}{N \Gamma} \sum_{k=1}^N \T \cdot \displaystyle \left( \prod_{j=1}^{N_k}  e^{-\beta f(j-1)} \cdot e^{-\beta \alpha(\abf^k)f(-\alpha(\bar{\abf}^k) + N_k)} \right) \cdot \frac{e^{-\beta \alpha(\bar{\abf}^k)f(-\alpha(\abf^k)+ N_k)}}{e^{-\beta \alpha(\abf^k)f(-\alpha(\bar{\abf}^k) +N_k)}} \\[10pt]
&= \frac{1}{N} \sum_{k=1}^N  \T \cdot \left( \frac{1}{\Gamma} \prod_{j=1}^{\mathcal{C}(\abf)} e^{-\beta f(j-1)}\right) \cdot \frac{e^{-\beta \alpha(\bar{\abf}^k)f(-\alpha(\abf^k)+ N_k)}}{e^{-\beta \alpha(\abf^k)f(-\alpha(\bar{\abf}^k) +N_k)}} \\[10pt]
&= \frac{1}{N} \sum_{k=1}^N  \T_{(\bar{\abf}^k, \abf^{-k}),(\abf^k, \abf^{-k})} \cdot \ubf_\abf \cdot \frac{e^{-\beta \alpha(\bar{\abf}^k)f(-\alpha(\abf^k)+ N_k)}}{e^{-\beta \alpha(\abf^k)f(-\alpha(\bar{\abf}^k) +N_k)}} \label{Eq: last-step-w-fraction} 
\end{align}
\\ \noindent The fraction inside the sum in  Eq. \ref{Eq: last-step-w-fraction} can be simplified as follows leading to further simplification of Eq. \ref{Eq: last-step-w-fraction}:
\begin{align}
\sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q} &= \frac{1}{N} \sum_{k=1}^N  \T_{(\bar{\abf}^k, \abf^{-k}),(\abf^k, \abf^{-k})} \cdot \ubf_\abf \cdot e^{sign(\abf^k) \beta f(N_k)} 
\label{Eq:only-need-to-replace-T-now}
\end{align}
\\ \noindent In Eq. \ref{Eq:only-need-to-replace-T-now} we can replace the element of the transition matrix $\T_{(\bar{\abf}^k, \abf^{-k}),(\abf^k, \abf^{-k})}$ by using the following: 
\begin{equation}
\T_{(\bar{\abf}^k, \abf^{-k}),(\abf^k, \abf^{-k})} = \frac{1}{1 + \displaystyle e^{\mathit{sign}(\abf^k) \beta f(N_k)}} 
\label{Eq:transition-matrix-T-symm-2-stgs}
\end{equation}
\\ \noindent Using the expression for the transition matrix element from Eq. \ref{Eq:transition-matrix-T-symm-2-stgs} into Eq. \ref{Eq:only-need-to-replace-T-now} and by using Eq. \ref{Eq:T_aa_u_a term}, we can simplify further: 
\begin{align}
\sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q} &= \frac{\ubf_\abf}{N} \sum_{k=1}^N \frac{1}{1 + \displaystyle e^{\mathit{sign}(\abf^k) \beta f(N_k)}} \cdot  e^{sign(\abf^k) \beta f(N_k)} \\[10pt]
&= \frac{\ubf_\abf}{N} \sum_{k=1}^N \frac{1}{1 + \displaystyle e^{\mathit{sign}(\bar{\abf}^k) \beta f(N_k)}}  \\[10pt]
&= \ubf_\abf - \ubf_\abf \T_{\abf,\abf}
\end{align}
\\ \noindent The final step in the previous simplification shows that Eq. \ref{Eq:transition-in-proof} holds for any $\abf \in \{\C,\D\}^N$. Therefore, the candidate distribution we propose in Eq. \ref{Eq:stationary-dist-symm-2-stgs-state} is the unique stationary distribution of the symmetric $N$-player game with two strategies. 
\end{proof}
\newpage
\begin{proof}
\textbf{Proof of Corollary} \ref{Lemma: Symmetric-2-stg} \\ \\
To show this result we count how many states are identical to a state $\abf \in \{\C,\D\}^N$ in a symmetric game. When players are symmetric in a two-strategy game, states can be enumerated by counting the number of $\C$ players in that state. This can also be confirmed by the expression of the stationary distribution in Eq. \ref{Eq:stationary-dist-symm-2-stgs-state}. Two distinct states $\abf, \abf'$ having the same number of cooperators (i.e., $\mathcal{C}(\abf') = \mathcal{C}(\abf)$), have the same stationary distribution probability (i.e., $\ubf_{\abf'} = \ubf_{\abf}$).
\\ \\ 
\noindent In a game with $N$ players, there can be $k$ players playing $\C$ in exactly $N \choose k$ ways. As argued before, all of these states are identical and are also equiprobable in the stationary distribution. Therefore, the stationary distribution probability of having $k$, $\C$ players, $\ubf_{k}$, is,
\begin{equation}
\ubf_{k} = \sum_{\forall \abf,  \mathcal{C(\abf)} = k} \ubf_\abf = \frac{1}{\Gamma} {N \choose k} \prod_{j=1}^k e^{-\beta f(j-1)} \\[10pt]
\end{equation} 
\noindent Where the normalization factor $\Gamma$ can also be simplified as: 
\begin{equation}
\Gamma = \sum_{k=0}^N {N \choose k} \prod_{j=1}^k e^{-\beta f(j-1)}
\end{equation}
\end{proof}
\newpage
\section*{Supplementary References}
\bibliographystyle{unsrt}
\bibliography{bibliography.bib }
\end{document}