\documentclass[11pt]{article}
\usepackage{times}
\usepackage{amsmath,amsthm,amssymb,mathtools,setspace,enumitem,epsfig,titlesec,verbatim,color,array,multirow,comment,graphicx,hyperref,blkarray}
%\usepackage[sort&compress]{natbib} % ProcB
\usepackage[super,sort&compress,comma]{natbib} % NComms
\usepackage[bf,small]{caption}
\usepackage[export]{adjustbox}
\usepackage[top=2.5cm,left=2.8cm,right=2.8cm,bottom=3.2cm]{geometry} 
\smallskip 

\definecolor{darkred}{rgb}{0.6,0,0}
\definecolor{darkblue}{rgb}{0,0.3,0.8}

\newcommand{\christian}[1]{\textcolor{blue}{{\bf CH:} #1}} 

\titleformat{\section}{\sffamily \fontsize{12}{20}\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\sffamily \fontsize{11}{20}\bfseries}{\thesubsection}{1em}{}

\renewcommand{\figurename}{Supplementary Figure}


\newcommand{\FigIllustration}{{\bf Fig.~1}}

\newtheoremstyle{plainCl1}% name
{9pt}%      Space above, empty = 'usual value'
{15pt}%      Space below
{\it}% 	   Body font
{}%         Indent amount (empty = no indent, \parindent = para indent)
{\bfseries}% Thm head font
{.}%        Punctuation after thm head
{2mm}% Space after thm head: \newline = linebreak
{}%         Thm head spec

\newtheoremstyle{plainCl2}% name
{9pt}%      Space above, empty = 'usual value'
{15pt}%      Space below
{\it}% 	   Body font
{}%         Indent amount (empty = no indent, \parindent = para indent)
{\bfseries}% Thm head font
{.}%        Punctuation after thm head
{4mm}% Space after thm head: \newline = linebreak
{}%         Thm head spec

\theoremstyle{plainCl1}
\newtheorem{theorem}{Theorem}
\newtheorem{Prop}{Proposition}
\newtheorem{definition}{Definition}

\theoremstyle{plainCl2}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{Cor}{Corollary}


\newcommand{\ALLD}{\emph{D}}

\newcommand{\A}{\mathbf{A}}
\newcommand{\abf}{\mathbf{a}}
\newcommand{\T}{\mathbf{T}}
\newcommand{\ubf}{\mathbf{u}}
\newcommand{\C}{\mathrm{C}}
\newcommand{\D}{\mathrm{D}}

\title{\sffamily \Large Supplementary Information\\[0.1cm] {\bfseries Introspection dynamics in asymmetric multiplayers games}}
\date{\empty}
\author{\parbox[c]{16cm}{\centering \onehalfspacing \fontsize{11}{12}\selectfont Marta Couto$^1$ and Saptarshi Pal$^1$\\[0.2cm]
$^1$Max Planck Research Group Dynamics of Social Behavior, Max Planck Institute for Evolutionary Biology, 24306~Ploen, Germany}}


\begin{document}
\maketitle
\onehalfspacing
\section*{The general model for introspection dynamics}
We consider a normal form game with $N (>2)$ players. Each player, $i$, has access to their action set, $\A^i$, in which there are $m^i$ possible actions that they can play, $\A^i = \{a^i_1, a^i_2, ..., a^i_{m^i}\}$. The payoff for an individual $i$ depends on what everyone plays and is represented by $\pi^i(\abf^1, \abf^2, ..., \abf^N)$, where $\abf := (\abf^1, \abf^2,...,\abf^N) \in \A^1 \times \A^2 \times ... \times \A^N =: \A$ represents a state of the game. In this model we only consider pure strategies for players. So, player $i$ has only $m^i$ possible strategies. Therefore, the total number of states possible for the game is the product of all $m^i$. 
\\ \\
\noindent We represent a state of the game, $\abf$, from the perspective of player $j$ as $\abf =: (\abf^j, \abf^{-j})$. In the state $(\abf^j, \abf^{-j})$, player $j$ plays the action $\abf^j \in \A^j$ and all the other co-players of $j$ play $\abf^{-j} \in \Pi_{k \neq j} \A^k$. The payoff of player $j$ in this state is also represented as $\pi^j(\abf^j, \abf^{-j})$.
\\ \\
\noindent The players update their strategies over time using the introspection dynamics \cite{couto2022introspection}. At every time step, one randomly chosen player can update their strategy. The randomly chosen player, say $j$, currently playing strategy $a^j_k$, compares their current payoff to the payoff that they would obtain if they played a randomly selected strategy,  $a^j_l \neq a^j_k$, from their action set $\A^j$. This comparison is done while assuming that the co-players do not change from $\abf^{-j}$. Then, they adopt this new strategy  with the probability: 

\begin{equation}
 p^j_{a^j_k \to a^j_l} (\abf^{-j})= \frac{1}{1 + e^{\displaystyle -\beta(\pi^j(a^j_l, \abf^{-j}) - \pi^j(a^j_k, \abf^{-j}))}}
 \label{Eq:introspection-update}
\end{equation}
\\
\noindent Where $\beta$ is the selection parameter. The probability that no update is made by the randomly chosen player is given by the normalization condition: 

\begin{equation}
 p^j_{a^j_k \to a^j_k} (\abf^{-j}) = 1 - \sum_{k \neq l} p^j_{a^j_k \to a^j_l} (\abf^{-j})
 \label{Eq:introspection-normalization}
\end{equation}
\\ 
\noindent Now, with the help of Eq. \ref{Eq:introspection-update} and \ref{Eq:introspection-normalization}, we can define the transition matrix $\T$ of the process. The transition matrix is a square matrix of size $M = m^1 \times m^2 \times ... \times m^N$. The element $\T_{\abf_p, \abf_q}$ of the matrix represents the probability that the game will go to state $\abf_q$ from state $\abf_p$ in a time step. Before defining the transition matrix, we define the notion of neighbouring states. 

\begin{definition}
\textbf{Neighbouring states}: \\ The state $\abf_q \in \mathit{Neb}(\abf_p)$, the neighbourhood of state $\abf_p$, if and only if $\exists j$ such that $\abf_p^{-j} = \abf_q^{-j}$ and $\abf_p^{j} \neq \abf_q^{j}$. 
\label{Def:neighbourhood-states}
\end{definition}
\noindent Note that if $\abf_q \in \mathit{Neb}(\abf_p)$ then by definition $\abf_p \in \mathit{Neb}(\abf_q)$. We give an example to explain the notion of neighbourhood. Consider three players, player $1,2$ and $3$. Each of these players choose actions from an identical binary action set $\{\mathit{0},\mathit{1}\}$. In this example, the state $(\mathit{0}, \mathit{0}, \mathit{0})$ is a neighbour of $(\mathit{0}, \mathit{0}, \mathit{1})$ and vice versa. The index of difference between the two states is player $3$. The states  $(\mathit{0}, \mathit{0}, \mathit{0})$ and $(\mathit{0}, \mathit{1}, \mathit{1})$ are not neighbouring states because more than one player's action are changed. 

\begin{definition}
\textbf{Index of difference for neighbouring states}: \\ \\ If the states $\abf_p$ and $\abf_q$ are neighbours then, the unique $j$ for which $\abf_p^{j} \neq \abf_q^{j}$, is called the index of difference. Or $I(\abf_p,\abf_q) := j$
\label{Def:index-of-difference}
\end{definition}
\noindent For the earlier example, let $\abf_p = (\mathit{0}, \mathit{0}, \mathit{0})$ and $\abf_q = (\mathit{0}, \mathit{0}, \mathit{1})$. Then, $I(\abf_p,\abf_q) = 3$. 
\\ \\ 
Using the above definitions of neighbourhood and index of difference, we can define the transition matrix $\T$ for the process as the follows: 
\begin{align}
\T_{\abf_p,\abf_q} = 
\begin{cases}
\frac{1}{N(m_j-1)}  \cdot p^j_{\abf^j_p \to \abf^j_q} (\abf_p^{-j}) \quad  \quad &\abf_p \in \mathit{Neb}(\abf_q) \quad \text{and,} \quad j = I(\abf_p,\abf_q)\\ \\ 
0 \quad & \abf_{p} \notin \mathit{Neb}(\abf_q) \\ \\
1 - \sum_{\forall \abf_k \neq \abf_p} \T_{\abf_p,\abf_k} \quad &\abf_p = \abf_q
\end{cases}
\label{Eq:transition-matrix}
\end{align}
\noindent The stochastic transition matrix $\T$ is row-stochastic. This implies that its stationary distribution is a left eigenvector of $\T$ corresponding to eigenvalue $1$. We denote the stationary distribution of $\T$ as $\ubf := (\ubf_{\abf})_{\abf \in \A}$. Furthermore, since no state of the process is isolated (i.e., every state has atleast one neighbour), a finite $\beta$ assures that a state is reachable from any other state with positive probability in a finite number of steps. Therefore, $\T$ is also primitive. The stationary distribution $\ubf$ is unique and strictly positive (from the Perron-Frobenius Theorem). The following conditions are satisfied by the stationary distribution $\ubf$ when it is additionally also a probability distribution. 

\begin{eqnarray}
\label{Eq:lefteigenvector}
\ubf \T = \ubf \\ 
\label{Eq:normalizationcondition}
\ubf \cdot \mathbf{1} = 1
\end{eqnarray}

\noindent The marginal distribution over the strategies of a player $j$ at the stationary distribution is given by $\mathbf{\xi}^j := (\mathbf{\xi}^j_{a^j_1}, \mathbf{\xi}^j_{a^j_2}, ..., \mathbf{\xi}^j_{a^j_{m_j}})$. This distribution indicates the probability with which player $j$ plays strategies from their action set $\A^j$ at the stationary distribution. The relationship between the marginal distribution and the stationary distribution is given by:

\begin{equation}
\mathbf{\xi}^j_{a^j_k} := \sum_{\mathbf{b} \in \A^{-j}} \ubf_{(a^j_k, \mathbf{b})}
\label{Eq:marginal-definition}
\end{equation}

\noindent Where, $\A^{-j} = \prod_{l \neq j} \A^l$. One can note that the marginal distribution is also a probability distribution. That is, for all $j$:

\begin{equation}
\sum_{a' \in \A^j} \xi^j_{a'}= 1
\label{Eq:marginal-prob-dist}
\end{equation}

\subsection*{Additive games and their properties under introspection dynamics}

In this subsection we discuss a special class of general multiplayer games: additive games \cite{mcavoy2015asymmetric} and some of their properties under the introspection dynamics. Additive games are games where the payoff earned by a player $j$ in the state $\abf$ can be broken down into two-components - one which is only dependent on what player $j$ played in the state: $\abf^j$ and the other which only depends on what their co-players $-j$ played in the state: $\abf^{-j}$ . That is, for all players $j$,

\begin{equation}
\pi^j(\abf) = \pi^j_{\abf^j} + \pi^j_{\abf^{-j}}
\label{Eq:additive games}
\end{equation}

\noindent holds. In additive games, the payoff difference earned by a player when they switch between two strategies in their action set is independent of what other co-players are playing (given all other co-players do not change their strategies). That is, for all $j$ and any pair of strategies $a^j_p, a^j_q\in \A^j$,

\begin{equation}
\pi^j(a^j_p, \mathbf{b}) - \pi^j(a^j_q, \mathbf{b}) = \pi^j_{a^j_p} - \pi^j_{a^j_q}
\label{Eq:additive games property}
\end{equation}

\noindent holds for any $\mathbf{b} \in \prod_{l \neq j} \A^l$. 
\\ \\
We see an example of additive game in the next section. Under introspection dynamics, stationary distribution and marginal distributions from additive games show interesting properties. They are discussed in the theorems below: 

\begin{theorem}
When $\beta$ is finite, the unique stationary distribution, $\ubf = (\ubf_\abf)_{\abf \in \A}$, of the introspection dynamics for the N-player additive game is given by: 
\begin{equation}
\ubf_a = \prod_{j=1}^N \frac{1}{\displaystyle \sum_{a' \in \A^j} e^{\beta \left( \pi^j_{a'} -  \pi^j_{\abf^j} \right) }} 
\label{Eq:additive-game-stationary-distribution}
\end{equation}
where, $\pi^j_{a'} - \pi^j_{\abf^j}$ is the co-player independent payoff difference that $j$  earns in an additive game when they unilaterally switch their play to $a'$ from $\abf^j$.
\label{Th:additive-games-stationary-dist}
\end{theorem}
\noindent The above theorem gives a closed form expression of the stationary distribution of the introspection dynamics for additive multiplayer games. For any finite value of the selection parameter, $\beta$, the stationary distribution can be analytically calculated using the expression in Eq. (\ref{Eq:additive-game-stationary-distribution}). The expression is derived by assuming that the update process of the introspection dynamics is governed by Eq. (\ref{Eq:introspection-update}) and (\ref{Eq:introspection-normalization}). For proof, see Appendix \ref{Section:Appendix}.

\begin{theorem}
Let $\ubf = (\ubf_\abf)_{\abf \in \A}$ be the unique stationary distribution of the introspection dynamics with finite $\beta$ for the N-player additive game. Then, $\ubf_\abf$ is the product of the marginal probabilities that each player plays their respective actions in $\abf$. That is, 

\begin{equation}
\ubf_\abf = \prod_{j = 1}^N \xi^j_{\abf^j}
\label{Eq:additive-game-products}
\end{equation}

\noindent where the marginal probability, $\xi^j_{\abf^j}$, is the cumulative probability that player $j$ plays $\abf^j$ at the stationary distribution. The marginal probability is given by: 

\begin{equation}
\xi^j_{\abf_j} = \frac{1}{\displaystyle \sum_{a' \in \A^j} e^{\beta \left( \pi^j_{a'} -  \pi^j_{\abf^j} \right) }} 
\label{Eq:marginal-at-additive-game}
\end{equation}
\noindent where, $\pi^j_{a'} - \pi^j_{\abf^j}$ is the co-player independent payoff difference that $j$  earns in an additive game when they unilaterally switch their play to $a'$ from $\abf^j$ in an additive game.
\label{Th:additive-game-product-of-marginals}
\end{theorem}

\noindent In other words, the above theorem states for additive games, the probability that the game will be in state $\abf = (\abf^1, \abf^2, ...,\abf^N)$ in the long run (considering a finite selection strength introspection dynamics) is the product of the cumulative probabilities that each player $j$ respectively adopts the action $\abf^j$ in the stationary distribution. \\ \\
\noindent To elucidate this result further, we use an example of a 2-player additive game where each player has three possible actions from the action set $\{\mathit{0},\mathit{1},\mathit{2}\}$. The result says that the expected frequency of the state $(\mathit{0,2})$, say, where player 1 and player 2 simultaneously play $\mathit{0}$ and $\mathit{2}$ respectively: $\ubf_{(\mathit{0,2})}$, is the product of the marginal probabilities that the first player plays $\mathit{0}$ and the second player plays $\mathit{2}$ in the game. That is, 

\begin{equation}
\ubf_{(\mathit{0,2})} = \xi^1_{\mathit{0}}  \xi^2_{\mathit{2}} = (\ubf_{(\mathit{0,0})} + \ubf_{(\mathit{0,1})} + \ubf_{(\mathit{0,2})})(\ubf_{(\mathit{0,2})} + \ubf_{(\mathit{1,2})} + \ubf_{(\mathit{2,2})}) 
\label{Eq:additive-stationary-dist-example}
\end{equation}
\\
\noindent As stated in the theorem above, this result holds for any additive game with arbitrary number of players and each player having arbitrary action sets.

\subsection*{Example of multiplayer additive game: linear public goods game}
We consider the linear public goods game with $N$ asymmetric players. Each player has two possible actions, to contribute (action, $\C$), or to not contribute (action, $\D$). The players differ in their cost of cooperation and their productivities. The cost of cooperation and the productivity of a player $i$ are denoted by $c^i$ and $r^i$.  The payoff for player $i$ when the state of the game is $\abf$ is given by: 

\begin{equation}
\pi^i(\abf) = \sum_{j=1}^N \frac{\displaystyle r^j a^j c^j}{N} - a^i c^i
\label{Eq:linear-pgg-payoff}
\end{equation}
\\
\noindent The difference in payoffs between playing the two actions in a linear public goods game is independent of what the other co-players play in the game. That is, 

\begin{equation}
\pi^i(\abf^i = \D, \abf^{-i}) - \pi^i(\abf^i = \C, \abf^{-i}) = c^i \left(1 - \frac{r^i}{N} \right) =: f(c^i, r^i) 
\label{Eq:difference-payoffs-lpgg}
\end{equation}
\\
\noindent is independent of $\abf^{-i}$. The linear public goods game is therefore an example of an additive game. This property of the game results in dominated strategies for player $i$ depending on the relationship between their productivity $r^i$ and number of players $N$. When $r^i < N$, the action of not contributing ($\D$) dominates the action of contributing ($\C$) and vice-versa. 
\\
\begin{lemma}
\label{prop:stationary-dist-lpgg}
When $\beta$ is finite, the unique stationary distribution of the introspection dynamics for an asymmetric linear public goods game under introspection dynamics is given by: 
\\
\begin{equation}
\ubf_\abf = \prod_{j = 1}^{N} \frac{1}{1 + \displaystyle e^{\mathit{sign}(\abf^j)\beta f(c^j, r^j )}} \quad ,\forall \abf \in \{\C, \D\}^N
\label{Eq:stationary_dist_lpgg}
\end{equation}
where, 
\begin{equation}
\label{Eq:sign-function}
\mathit{sign}(a) =
\begin{cases}
1& \quad \text{if} \quad a = \C \\
-1& \quad \text{if} \quad a = \D
\end{cases}
\end{equation}
\end{lemma}

\section*{Symmetric multiplayer games with two strategies}

In the previous section we looked at properties of the stationary distribution of the introspection dynamics for additive games. In this section we look at properties of the stationary distribution for any multiplayer game where players are symmetric and have two actions in their action set. A $N-$player symmetric normal form game satisfies the following properties: 

\begin{enumerate}
\item $\A^1 = \A^2 = ... = \A^N = \mathcal{A}$, and
\item For any $i, j \in \{1,2,...,N\}, a \in \mathcal{A}$ and $\mathbf{b} \in \displaystyle \prod_{k=1}^{N-1} \mathcal{A}$: 
\begin{equation}
\pi^i(a, \mathbf{b}) = \pi^j(a, \mathbf{b})
\end{equation}
\end{enumerate}

\noindent In addition, when there are only two actions in the action set of players we define the action set in the same way as we did in the section of linear public goods game: $\mathcal{A} := \{\C, \D\}$. Since all players are symmetric in the two-action game, the number of states of the game can be reduced from  $2^N$ to $N+1$. Now, the state $k$ corresponds to $k$ players playing $\C$ and $N-k$ players playing $\D$. For the sake of notational simplicity, we denote the payoffs of a $\C$ and $\D$ player in the state $k$ as $\pi^{\C}(k)$ and $\pi^{\D}(k)$ respectively. 

%We define following mapping function:  
%
%\begin{equation}
%e(a^i):= 
%\begin{cases}
%1 \quad \text{if} \quad a^i = a_\C \\
%0 \quad \text{if} \quad a^i = a_\D  
%\end{cases}
%\end{equation}
%\\
%We define $N_\C(\abf)$ as the number of $\C$ players in a state $\abf$. That is, 
%
%\begin{equation}
%N_\C(\abf) := \sum_{i = 1}^N e(\abf^i)
%\end{equation}
%\noindent 
%\\
\begin{lemma}
When $\beta$ is finite, the unique stationary distribution, $(\ubf_k)_{k \in \{0,1,...,N\}}$, of the introspection dynamics for the $N-$player symmetric normal form game with two actions, $\mathcal{A} = \{a_\C, a_\D \}$, is given by:
\begin{equation}
\label{Eq:stationary-dist-symm-2-stgs}
\ubf_k = \frac{1}{T(k)} \cdot {N \choose k} \cdot \displaystyle \prod_{j=0}^{k} \displaystyle e^{\beta f(j-1)}
\end{equation}
where, $f(j) := \pi^\D(k+1) - \pi^\C(k)$ and $T(k)$ is the normalization factor, given by,
\begin{equation}
\label{Eq:normalization-Tk}
T(k) = \displaystyle \sum_{k=0}^N {N \choose k} \cdot \displaystyle \prod_{j=0}^{k} \displaystyle e^{\beta f(j-1)}
\end{equation}
\end{lemma}

\section*{Appendix: Proofs}
\label{Section:Appendix}
\begin{proof}
\textbf{Proof of Theorem} \ref{Th:additive-games-stationary-dist} \\ \\ 
Since $\beta$ is finite, the transition matrix of the process $\T$ given by Eq. \ref{Eq:transition-matrix} is primitive and therefore, the stationary distribution $\ubf = (\ubf_\abf)_{\abf \in \A}$ of the row-stochastic transition matrix is unique and satisfies the conditions laid out in Eq. \ref{Eq:lefteigenvector} and \ref{Eq:normalizationcondition}. To continue for the rest of the proof, we introduce some short-cut notation that will be of use later in the proof:\\
\begin{align}
I_{q} &:= I(\abf_q,\abf), \quad \mathit{iff} \quad \abf_q \in \mathit{Neb}(\abf) \\ \notag \\ 
\label{Eq:shortcut-tau}
\tau^j_{\abf^j} &:= \frac{1}{\displaystyle \sum_{a' \in \A^j} e^{\beta \left( \pi^j_{a'} -  \pi^j_{\abf^j} \right) }} 
\end{align}
\noindent In order to show that the candidate stationary distribution, as proposed in Eq. \ref{Eq:additive-game-stationary-distribution} is the stationary distribution of the process, we need to show that the following are true:
\begin{eqnarray}
\label{step-one}
\T_{\abf,\abf} \ubf_\abf  + \sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q}= \ubf_a \quad \forall \abf \in \A \\ 
\label{step-two}
\sum_{\abf \in \A} \ubf_\abf  = 1
\end{eqnarray}
The Eq \ref{step-one} can be simplified further with the steps: 
\begin{align}
&\T_{\abf,\abf} \ubf_\abf  + \sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q}= \\
& \left( 1 - \frac{1}{N} \sum_{\abf_q \in \mathit{Neb}(\abf)} \frac{1}{m^{I_q}-1} \cdot p^{I_q}_{\abf^{I_q} \to \abf^{I_q}_q} \cdot \ubf_{\abf} \right) + \sum_{\abf_q \in \mathit{Neb}(\abf)}  \frac{1}{m^{I_q}-1} \cdot p^{I_q}_{\abf^{I_q}_q \to \abf^{I_q}} \cdot \ubf_{\abf_q} = \\ \notag \\
\label{eq:important-step}
& \ubf_\abf +  \frac{1}{N} \sum_{\abf_q \in \mathit{Neb}(\abf)} \left( \prod_{k \neq I_q} \tau^k_{\abf^k} \right) \left( p^{I_q}_{\abf^{I_q}_q \to \abf^{I_q}} \cdot \tau^{I_q}_{\abf^{I_q}} -  p^{I_q}_{\abf^{I_q} \to \abf^{I_q}_q} \cdot \tau^{I_q}_{\abf^{I_q}_q} \right) \cdot \left(  \frac{1}{m^{I_q}-1} \right)
\end{align}
\\ Using the definition of probability of update of the introspection dynamics, as given by Eq. \ref{Eq:introspection-update} and Eq. \ref{Eq:shortcut-tau}, it can be shown that: 
\begin{equation}
p^{I_q}_{\abf^{I_q}_q \to \abf^{I_q}} \cdot \tau^{I_q}_{\abf^{I_q}} -  p^{I_q}_{\abf^{I_q} \to \abf^{I_q}_q} \cdot \tau^{I_q}_{\abf^{I_q}_q} = 0
\label{important-step-is-zero}
\end{equation}
\\ \noindent Plugging the equality in Eq. \ref{important-step-is-zero} into Eq. \ref{eq:important-step}, we can see that the left hand side of Eq. \ref{step-one} indeed simplifies to $\ubf_{\abf}$. Now, to confirm that the candidate $\ubf$ is the unique stationary distribution we need to check if Eq. \ref{step-two} holds. Simplifying the left hand side of this equation shows that:
\begin{align}
\sum_{\abf \in \A} \ubf_\abf &= \sum_{\abf \in \A} \prod_{k=1}^N \tau^k_{\abf^k} \\ \notag \\
\label{step-prod-sum-sum-prod}
&= \left( \prod_{k=1}^N \sum_{\abf' \in \A} \displaystyle e^{\beta \pi^k_{\abf'}}\right)^{-1} \cdot \left( \sum_{\abf \in \A} \prod_{k=1}^N \displaystyle e^{\beta \pi^k_{\abf^k}} \right) \\ \notag \\
\label{step-prod-is-one}
&= 1
\end{align}
\noindent The step from Eq. \ref{step-prod-sum-sum-prod} to Eq \ref{step-prod-is-one} is possible because the sum and product in Eq. \ref{step-prod-sum-sum-prod} are interchangeable for both the terms. Therefore, condition Eq. \ref{step-two} is satisfied too. 
\end{proof}

\begin{proof}
\textbf{Proof of Theorem} \ref{Th:additive-game-product-of-marginals} \\ \\ 
If $\ubf$ is the unique stationary distribution of the $N-$player additive game with under the finite selection introspection dynamics, it is given by the expression in Eq. \ref{Eq:additive-game-stationary-distribution}. We calculate the marginal distribution of any arbitrary state $\abf$, $\xi_{\abf} = (\xi^j_{\abf^j})_{j = 1,2,...,N}$ by using the definition of marginal distribution in Eq. \ref{Eq:marginal-definition}. It follows that: 
\begin{align}
\xi^j_{\abf^j} &= \sum_{\mathbf{b} \in \A^{-j}} \ubf_{(\abf^j,\mathbf{b})} \\ \notag \\
&= \left( \prod_{k=1}^N \sum_{\abf' \in \A^k} \displaystyle e^{\beta \pi^k_{\abf'}}\right)^{-1} \cdot \displaystyle e^{\beta \pi^j_{\abf^j}} \cdot \left( \sum_{\mathbf{b} \in \A^{-j}} \prod_{k \neq j} e^{\beta \pi^k_{\mathbf{b}^k}} \right) \\ \notag \\
&= \left( \sum_{\abf' \in \A^j} \displaystyle e^{\beta \pi^j_{\abf'}}\right)^{-1} \cdot \displaystyle e^{\beta \pi^j_{\abf^j}} \cdot \left( \prod_{k\neq j} \sum_{\abf' \in \A^k} \displaystyle e^{\beta \pi^k_{\abf'}}\right)^{-1} \cdot \left( \sum_{\mathbf{b} \in \A^{-j}} \prod_{k \neq j} e^{\beta \pi^k_{\mathbf{b}^k}} \right) \\ \notag \\ 
&= \left( \sum_{\abf' \in \A^j} \displaystyle e^{\beta \pi^j_{\abf'}}\right)^{-1} \cdot \displaystyle e^{\beta \pi^j_{\abf^j}} \cdot \left( \sum_{\abf' \in \A^{-j}} \prod_{k\neq j}  \displaystyle e^{\beta \pi^k_{\abf'}}\right)^{-1} \cdot \left( \sum_{\mathbf{b} \in \A^{-j}} \prod_{k \neq j} e^{\beta \pi^k_{\mathbf{b}^k}} \right) \\ \notag \\ 
&= \left( \sum_{\abf' \in \A^j} \displaystyle e^{\beta \left( \pi^j_{\abf'} - \pi^j_{\abf^j}\right)}\right)^{-1}
\end{align}
\noindent Therefore, the marginal distribution follows Eq.  \ref{Eq:marginal-at-additive-game}. Now since we also additionally know that the stationary distribution follows the form Eq. \ref{Eq:additive-game-stationary-distribution}, we can conclude that for additive games, under introspection dynamics with finite selection, Eq. \ref{Eq:additive-game-products} holds. 
\end{proof}

\begin{proof}
\textbf{Proof of lemma} \ref{prop:stationary-dist-lpgg} \\ \\
Since we have demonstrated that the linear public goods game is an additive game, the proof of this theorem can be performed by directly using Theorem \ref{Th:additive-games-stationary-dist}. Here, we provide an independent proof. The idea behind this proof is identical to the proof of Theorem \ref{Th:additive-games-stationary-dist}. \\ \\
\noindent The stationary transition matrix $\T$ for the linear public goods game is primitive when $\beta$ is finite (i.e., there is a positive power $k$ such that $\T^k$ is a strictly positive matrix). Therefore, the stationary distribution of $\T$ will always be unique. We define the following short cut notations for the ease of the proof: 
\begin{eqnarray}
&\bar{\abf}^j := \{a_\D,a_\C\} \setminus \abf^j  \\ 
&p^j := \frac{1}{1 + \displaystyle e^{\beta f(c^j, r^j)}}
\end{eqnarray}
Using these notations and Eq. \ref{Eq:introspection-update} and \ref{Eq:difference-payoffs-lpgg} we can write the probability that a player $j$ updates from $\abf^j$ to $\bar{\abf}^j$ while their co-players play $\abf^{-j}$ as:
\begin{equation}
p^j_{\displaystyle \bar{\abf}^j  \to \abf^j} (\abf^{-j}) = p^j \mathit{sign}(\abf^j) + \bar{\abf}^j \\ \\
\end{equation}
The candidate stationary distribution $\ubf$ given in Eq \ref{Eq:stationary_dist_lpgg} can be written down using our shortcut notation as: 
\begin{equation}
\label{Eq:stationary-dist-shortcut}
\ubf_\abf = \prod_{k = 1}^{N}  p^k \mathit{sign}(\abf^k) + \bar{\abf}^k \quad ,\forall \abf \in \{0,1\}^N
\end{equation}
This stationary distribution must satisfy the following properties, which are also given in Eq  \ref{Eq:lefteigenvector} and \ref{Eq:normalizationcondition}:
\begin{align}
\label{Eq:transition-in-proof}
&\ubf_\abf = \T_{\abf,\abf} \ubf_a  + \sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q}  \\ 
\label{Eq:normalization-in-proof}
&\sum_{\forall \abf_q} u_{\abf_q}= 1
\end{align}
Where, the terms in the right hand side of Eq. \ref{Eq:transition-in-proof} can be simplified using Eq \ref{Eq:introspection-update} and \ref{Eq:transition-matrix} as follows:
\begin{eqnarray}
\T_{\abf,\abf} = 1 - \sum_{k=1}^{N} \T_{(\abf^k, \abf^{-k}), (\bar{\abf}^k,\abf^{-k})} = 1 - \frac{1}{N} \sum_{k=1}^{N} p^k \textit{sign}(\bar{\abf}^k) + \abf^k 
\label{Eq:first-term-rhs-proof}
\end{eqnarray} 
and additionally, also using Eq. \ref{Eq:stationary-dist-shortcut} the second term can be simplified too:
\begin{align}
\sum_{\abf_q \neq \abf} \T_{\abf_q, \abf} \ubf_{\abf_q} &= \sum_{k = 1}^N \T_{(\bar{\abf}^k,\abf^{-k}), (\abf^k, \abf^{-k})} \ubf_{(\bar{\abf}^k,\abf^{-k})} \\
&= \frac{1}{N} \sum_{k = 1}^N \left(p^k \textit{sign}(\abf^k) + \bar{\abf}^k \right) \ubf_{(\bar{\abf}^k,\abf^{-k})} \\ 
\label{Eq:second-term-rhs-proof}
&= \frac{\ubf_\abf}{N} \sum_{k=1}^{N} p^k \textit{sign}(\bar{\abf}^k) + \abf^k 
\end{align}
Now, using Eq. \ref{Eq:first-term-rhs-proof}, \ref{Eq:second-term-rhs-proof} one can show that the right hand side of Eq. \ref{Eq:transition-in-proof} is the element of the stationary distribution, corresponding to the state $\abf$, $\ubf_a$.  Now, to complete the proof, we must show that Eq. \ref{Eq:normalization-in-proof} is also true for our candidate stationary distribution. This can be done by decomposing the sum of the elements of the stationary distribution as follows:
\begin{eqnarray}
\sum_{\forall \abf_q} u_{\abf_q} =& \displaystyle \sum_{\forall \abf_q} \prod_{k=1}^N p^k \mathit{sign}(\abf_q^k) + \bar{\abf}_q^k \\
=& \displaystyle \displaystyle \sum_{\forall \abf_q} (1-p^N)  \prod_{k=1}^{N-1} p^k \mathit{sign}(\abf_q^k) + \bar{\abf}_q^k  + p^N  \prod_{k=1}^{N-1} p^k \mathit{sign}(\abf_q^k) + \bar{\abf}_q^k \\ 
=& \displaystyle \sum_{\forall \abf_q} \prod_{k=1}^{N-1} p^k \mathit{sign}(\abf_q^k) + \bar{\abf}_q^k
\end{eqnarray}
When the above decomposition is perfomed $N-1$ more times, the sum of the right hand side becomes 1. This prooves that the candidate stationary distribution is also a probability distribution.
\end{proof}


\section*{Supplementary References}
\bibliographystyle{unsrt}
\bibliography{bibliography.bib }
\end{document}